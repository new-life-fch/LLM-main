# CausalEditor å¿«é€Ÿä½¿ç”¨æŒ‡å—

## å¿«é€Ÿå¼€å§‹ï¼ˆ3æ­¥éª¤ï¼‰

### ç¬¬1æ­¥ï¼šé¢„è®¡ç®—çŸ¥è¯†æŒ‡çº¹
```bash
# ä»Wikidataæå–10000ä¸ªçŸ¥è¯†ä¸‰å…ƒç»„å¹¶æ„å»ºæ¿€æ´»æŒ‡çº¹
python scripts/precompute_causal_knowledge.py \
    --model-name meta-llama/Llama-2-7b-hf \
    --output-dir ./precomputed_data/llama2-7b \
    --knowledge-type wikidata \
    --limit 10000 \
    --device cuda
```

### ç¬¬2æ­¥ï¼šä½¿ç”¨CausalEditor
```python
from modeling_llms.modeling_llama_causal import CausalLlamaForCausalLM
from transformers import AutoTokenizer

# åŠ è½½é›†æˆCausalEditorçš„æ¨¡å‹
model = CausalLlamaForCausalLM.from_pretrained_with_causal_editor(
    model_name_or_path="meta-llama/Llama-2-7b-hf",
    vector_db_path="./precomputed_data/llama2-7b/vector_database",
    edit_strength=1.0,
    top_layers=10
)

tokenizer = AutoTokenizer.from_pretrained("meta-llama/Llama-2-7b-hf")
model.set_tokenizer(tokenizer)

# ç”Ÿæˆæ— å¹»è§‰æ–‡æœ¬
question = "What year did Einstein publish his paper on the photoelectric effect?"
inputs = tokenizer(question, return_tensors="pt").to("cuda")
outputs = model.generate(**inputs, max_new_tokens=50)
answer = tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)
print(answer)  # åº”è¯¥è¾“å‡ºï¼š1905å¹´
```

### ç¬¬3æ­¥ï¼šè¯„ä¼°æ•ˆæœ
```bash
# åœ¨TruthfulQAä¸Šè¯„ä¼°
python scripts/evaluate_truthfulqa_causal.py \
    --model-path meta-llama/Llama-2-7b-hf \
    --vector-db-path ./precomputed_data/llama2-7b/vector_database \
    --output-dir ./results/evaluation \
    --mode both
```

## ä¸»è¦ç‰¹æ€§

### ğŸ¯ ç²¾ç¡®ç¼–è¾‘
- **å¤–ç§‘æ‰‹æœ¯å¼ä¿®æ­£**ï¼šåªä¿®æ”¹é”™è¯¯çš„å…³é”®äº‹å®ï¼Œä¿æŒè¯­è¨€æµç•…æ€§
- **å®æ—¶æ£€æµ‹**ï¼šæ¨ç†æ—¶åŠ¨æ€æ£€æµ‹å› æœå†²çª
- **æœ€å°å‰¯ä½œç”¨**ï¼šç›¸æ¯”RAGç­‰æ–¹æ³•ï¼Œå¯¹åŸæ–‡æ”¹åŠ¨æœ€å°

### âš¡ é«˜æ•ˆæ¨ç†
- **ä½å»¶è¿Ÿ**ï¼šæ¨ç†æ—¶é—´å¢åŠ <10%
- **å•å¡å‹å¥½**ï¼šæ”¯æŒåœ¨å•å¼ GPUä¸Šè¿è¡Œ
- **å¯æ‰©å±•**ï¼šæ”¯æŒå¢é‡æ›´æ–°çŸ¥è¯†åº“

### ğŸ”§ æ˜“äºä½¿ç”¨
- **å³æ’å³ç”¨**ï¼šä¸ç°æœ‰Transformersæ¨¡å‹æ— ç¼é›†æˆ
- **é…ç½®çµæ´»**ï¼šä¸°å¯Œçš„å‚æ•°è°ƒä¼˜é€‰é¡¹
- **å·¥å…·å®Œæ•´**ï¼šæä¾›å®Œæ•´çš„é¢„è®¡ç®—å’Œè¯„ä¼°å·¥å…·

## é…ç½®è°ƒä¼˜

### å…³é”®å‚æ•°è¯´æ˜
```python
model = CausalLlamaForCausalLM.from_pretrained_with_causal_editor(
    # åŸºç¡€é…ç½®
    model_name_or_path="meta-llama/Llama-2-7b-hf",
    vector_db_path="./path/to/vector_database",
    
    # ç¼–è¾‘å¼ºåº¦ï¼šæ§åˆ¶ä¿®æ­£å¹…åº¦ (0.1-3.0)
    edit_strength=1.0,
    
    # ç¼–è¾‘å±‚æ•°ï¼šå‚ä¸ç¼–è¾‘çš„é¡¶å±‚æ•°é‡ (5-20)
    top_layers=10,
    
    # ç›¸ä¼¼åº¦é˜ˆå€¼ï¼šæ¿€æ´»æ£€ç´¢çš„æœ€ä½ç›¸ä¼¼åº¦ (0.5-0.9)
    similarity_threshold=0.8,
    
    # å†²çªé˜ˆå€¼ï¼šè§¦å‘ç¼–è¾‘çš„å†²çªç¨‹åº¦ (0.3-0.8)
    conflict_threshold=0.6
)
```

### æ€§èƒ½è°ƒä¼˜å»ºè®®
- **ç¼–è¾‘å¼ºåº¦**ï¼šä»1.0å¼€å§‹ï¼Œå¦‚æœä¿®æ­£ä¸è¶³å¯å¢åŠ åˆ°1.5-2.0
- **å±‚æ•°é€‰æ‹©**ï¼šæ¨¡å‹å±‚æ•°çš„1/3å·¦å³é€šå¸¸æ•ˆæœæœ€ä½³
- **é˜ˆå€¼è®¾ç½®**ï¼šé«˜é˜ˆå€¼=é«˜ç²¾åº¦ä½å¬å›ï¼Œä½é˜ˆå€¼=é«˜å¬å›ä½ç²¾åº¦

## å¸¸è§ç”¨ä¾‹

### ç”¨ä¾‹1ï¼šç§‘å­¦äº‹å®ä¿®æ­£
```python
questions = [
    "What year was the theory of relativity published?",
    "Who discovered DNA structure?", 
    "When did World War II end?"
]

for q in questions:
    inputs = tokenizer(q, return_tensors="pt").to("cuda")
    outputs = model.generate(**inputs, max_new_tokens=30)
    answer = tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)
    print(f"Q: {q}")
    print(f"A: {answer}\n")
```

### ç”¨ä¾‹2ï¼šå¤šé€‰é¢˜è¯„ä¼°
```python
# è®¾ç½®å¤šé€‰é¢˜æ¨¡å¼
model.set_generation_mode(is_mc=True, prompt_length=len(question_tokens))

# è®¡ç®—ç­”æ¡ˆæ¦‚ç‡
prob_true = model.get_answer_probability(question, correct_answer)
prob_false = model.get_answer_probability(question, wrong_answer)
```

### ç”¨ä¾‹3ï¼šæ‰¹é‡å¤„ç†
```python
# æ‰¹é‡ç”Ÿæˆï¼ˆæ¨èæ–¹å¼ï¼‰
questions = ["question1", "question2", "question3"]
answers = model.batch_generate(questions, max_new_tokens=50)
```

## è¿›é˜¶åŠŸèƒ½

### è‡ªå®šä¹‰çŸ¥è¯†æº
```python
# ä½¿ç”¨CSVæ–‡ä»¶ä½œä¸ºçŸ¥è¯†æº
python scripts/precompute_causal_knowledge.py \
    --knowledge-type csv \
    --csv-path ./custom_knowledge.csv \
    --limit 5000
```

CSVæ ¼å¼è¦æ±‚ï¼š
```csv
subject,relation,object,confidence,text
Einstein,published_paper_on,Photoelectric Effect,1.0,Einstein published a paper on the photoelectric effect.
Einstein,published_year,1905,1.0,Einstein published his paper in 1905.
```

### å¢é‡æ›´æ–°
```python
# æ·»åŠ æ–°çŸ¥è¯†åˆ°ç°æœ‰æ•°æ®åº“
python scripts/precompute_causal_knowledge.py \
    --incremental \
    --existing-db-path ./precomputed_data/llama2-7b/vector_database \
    --knowledge-type csv \
    --csv-path ./new_knowledge.csv \
    --limit 1000
```

### ç»Ÿè®¡ç›‘æ§
```python
# è·å–å®æ—¶ç»Ÿè®¡
stats = model.get_causal_editor_statistics()
print(f"å†²çªæ£€æµ‹ç‡: {stats['conflict_detector_stats']['conflict_rate']:.3f}")
print(f"ç¼–è¾‘æˆåŠŸç‡: {stats['counterfactual_editor_stats']['success_rate']:.3f}")
print(f"å¹³å‡ç¼–è¾‘å¹…åº¦: {stats['counterfactual_editor_stats']['average_edit_magnitude']:.3f}")
```

## é—®é¢˜æ’æŸ¥

### Q: é¢„è®¡ç®—é˜¶æ®µæ˜¾å­˜ä¸è¶³ï¼Ÿ
```bash
# é™ä½æ‰¹å¤„ç†å¤§å°
python scripts/precompute_causal_knowledge.py --batch-size 4

# æˆ–ä½¿ç”¨CPUï¼ˆè¾ƒæ…¢ï¼‰
python scripts/precompute_causal_knowledge.py --device cpu
```

### Q: Wikidataè®¿é—®è¶…æ—¶ï¼Ÿ
```bash
# å¢åŠ è¯·æ±‚é—´éš”
python scripts/precompute_causal_knowledge.py --rate-limit 2.0

# æˆ–ä½¿ç”¨æœ¬åœ°CSVæ–‡ä»¶
python scripts/precompute_causal_knowledge.py --knowledge-type csv --csv-path ./local_data.csv
```

### Q: ç¼–è¾‘æ•ˆæœä¸æ˜æ˜¾ï¼Ÿ
```python
# å¢åŠ ç¼–è¾‘å¼ºåº¦
model = CausalLlamaForCausalLM.from_pretrained_with_causal_editor(
    # ... å…¶ä»–å‚æ•°
    edit_strength=1.5,  # ä»1.0å¢åŠ åˆ°1.5
    top_layers=15       # å¢åŠ ç¼–è¾‘å±‚æ•°
)
```

### Q: æ¨ç†é€Ÿåº¦è¾ƒæ…¢ï¼Ÿ
```python
# å‡å°‘ç¼–è¾‘å±‚æ•°
model = CausalLlamaForCausalLM.from_pretrained_with_causal_editor(
    # ... å…¶ä»–å‚æ•°
    top_layers=5,                    # å‡å°‘å±‚æ•°
    similarity_threshold=0.9         # æé«˜é˜ˆå€¼ï¼Œå‡å°‘æ£€ç´¢
)
```

## å®éªŒå¤ç°

### å¤ç°è®ºæ–‡ä¸»å®éªŒ
```bash
# 1. é¢„è®¡ç®—ï¼ˆçº¦2-4å°æ—¶ï¼‰
python scripts/precompute_causal_knowledge.py \
    --model-name meta-llama/Llama-2-7b-hf \
    --limit 10000 \
    --output-dir ./precomputed_data/llama2-7b

# 2. TruthfulQAè¯„ä¼°ï¼ˆçº¦1-2å°æ—¶ï¼‰  
python scripts/evaluate_truthfulqa_causal.py \
    --model-path meta-llama/Llama-2-7b-hf \
    --vector-db-path ./precomputed_data/llama2-7b/vector_database \
    --output-dir ./results/truthfulqa_main \
    --mode both

# 3. æŸ¥çœ‹ç»“æœ
cat ./results/truthfulqa_main/evaluation_summary.json
```

### é¢„æœŸæ”¹è¿›æ•ˆæœ
- **TruthfulQA MC1å‡†ç¡®ç‡**: +15~25%
- **TruthfulQA MC2å‡†ç¡®ç‡**: +10~20%  
- **ç”Ÿæˆè´¨é‡**: æ˜¾è‘—å‡å°‘äº‹å®æ€§é”™è¯¯
- **æ¨ç†å»¶è¿Ÿ**: å¢åŠ <10%

---

æ›´å¤šè¯¦ç»†ä¿¡æ¯è¯·å‚è€ƒ [README_CausalEditor.md](./README_CausalEditor.md) 